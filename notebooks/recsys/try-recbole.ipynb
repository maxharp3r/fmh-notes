{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try recbole\n",
    "\n",
    "<https://recbole.io/docs/user_guide/usage/use_modules.html>\n",
    "\n",
    "Notes:\n",
    "\n",
    "* recbole fails to train a model with numpy 1.24 or greater (\"AttributeError: module 'numpy' has no attribute 'float'.\"). Downgrade to 1.23\n",
    "* mps doesn't seem to be supported, so fall back to cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that python was installed with tcl-tk\n",
    "import tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.general_recommender import BPR\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from recbole.model.loss import BPRLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = BPRLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.2372, -0.9604,  1.5415], requires_grad=True),\n",
       " tensor([-0.4079,  0.8806,  0.0529], requires_grad=True))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_score = torch.randn(3, requires_grad=True)\n",
    "neg_score = torch.randn(3, requires_grad=True)\n",
    "\n",
    "pos_score, neg_score\n",
    "# output = loss(pos_score, neg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8382, 0.1369, 0.8159], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(pos_score - neg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1765, 1.9882, 0.2035], grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.log(torch.sigmoid(pos_score - neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7894, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 1e-10\n",
    "\n",
    "-torch.log(gamma + torch.sigmoid(pos_score - neg_score)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7894, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(pos_score, neg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18 Sep 14:44    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /Users/maxharp3r/Library/Caches/pypoetry/virtualenvs/fmh-notes-FjPe97EK-py3.11/lib/python3.11/site-packages/recbole/config/../dataset_example/ml-100k\n",
      "checkpoint_dir = saved\n",
      "show_progress"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = None\n",
      "item_inter_num_interval = None\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = True\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = None\n",
      "relation_kg_num_interval = None\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "eval_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configurations initialization\n",
    "config = Config(model=\"BPR\", dataset=\"ml-100k\")\n",
    "\n",
    "# init random seed\n",
    "init_seed(config[\"seed\"], config[\"reproducibility\"])\n",
    "\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "\n",
    "# write config info into log\n",
    "logger.info(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18 Sep 14:25    INFO  ml-100k\n",
      "The number of users: 944\n",
      "Average actions of users: 106.04453870625663\n",
      "The number of items: 1683\n",
      "Average actions of items: 59.45303210463734\n",
      "The number of inters: 100000\n",
      "The sparsity of the dataset: 93.70575143257098%\n",
      "Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "# dataset creating and filtering\n",
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18 Sep 14:25    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "18 Sep 14:25    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}]\n",
      "18 Sep 14:25    INFO  BPR(\n",
      "  (user_embedding): Embedding(944, 64)\n",
      "  (item_embedding): Embedding(1683, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 168128\n"
     ]
    }
   ],
   "source": [
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "# model loading and initialization\n",
    "model = BPR(config, train_data.dataset).to(config[\"device\"])\n",
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " The batch_size of interaction: 2048\n",
       "     user_id, torch.Size([2048]), cpu, torch.int64\n",
       "     item_id, torch.Size([2048]), cpu, torch.int64\n",
       "     rating, torch.Size([2048]), cpu, torch.float32\n",
       "     timestamp, torch.Size([2048]), cpu, torch.float32\n",
       "     neg_item_id, torch.Size([2048]), cpu, torch.int64\n",
       " )"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(enumerate(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mml-100k\u001b[0m\n",
       "\u001b[1;34mThe number of users\u001b[0m: 944\n",
       "\u001b[1;34mAverage actions of users\u001b[0m: 85.69247083775186\n",
       "\u001b[1;34mThe number of items\u001b[0m: 1683\n",
       "\u001b[1;34mAverage actions of items\u001b[0m: 48.974545454545456\n",
       "\u001b[1;34mThe number of inters\u001b[0m: 80808\n",
       "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 94.91374361763195%\n",
       "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id', 'rating', 'timestamp', 'neg_item_id']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch_idx, batched_data in enumerate(train_data):\n",
    "\n",
    ".dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "User specified autocast device_type must be 'cuda' or 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/maxharp3r/code/fmh-notes/notebooks/recsys/try-recbole.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maxharp3r/code/fmh-notes/notebooks/recsys/try-recbole.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(config, model)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maxharp3r/code/fmh-notes/notebooks/recsys/try-recbole.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# model training\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maxharp3r/code/fmh-notes/notebooks/recsys/try-recbole.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m best_valid_score, best_valid_result \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mfit(train_data, valid_data)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/fmh-notes-FjPe97EK-py3.11/lib/python3.11/site-packages/recbole/trainer/trainer.py:440\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_data, valid_data, verbose, saved, show_progress, callback_fn)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mfor\u001b[39;00m epoch_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_epoch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs):\n\u001b[1;32m    438\u001b[0m     \u001b[39m# train\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     training_start_time \u001b[39m=\u001b[39m time()\n\u001b[0;32m--> 440\u001b[0m     train_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_epoch(\n\u001b[1;32m    441\u001b[0m         train_data, epoch_idx, show_progress\u001b[39m=\u001b[39;49mshow_progress\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    443\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loss_dict[epoch_idx] \u001b[39m=\u001b[39m (\n\u001b[1;32m    444\u001b[0m         \u001b[39msum\u001b[39m(train_loss) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(train_loss, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m train_loss\n\u001b[1;32m    445\u001b[0m     )\n\u001b[1;32m    446\u001b[0m     training_end_time \u001b[39m=\u001b[39m time()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/fmh-notes-FjPe97EK-py3.11/lib/python3.11/site-packages/recbole/trainer/trainer.py:245\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, train_data, epoch_idx, loss_func, show_progress)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_reduce_hook()\n\u001b[1;32m    243\u001b[0m     sync_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msync_grad_loss()\n\u001b[0;32m--> 245\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39;49mautocast(device_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice\u001b[39m.\u001b[39;49mtype, enabled\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_amp):\n\u001b[1;32m    246\u001b[0m     losses \u001b[39m=\u001b[39m loss_func(interaction)\n\u001b[1;32m    248\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(losses, \u001b[39mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/fmh-notes-FjPe97EK-py3.11/lib/python3.11/site-packages/torch/amp/autocast_mode.py:201\u001b[0m, in \u001b[0;36mautocast.__init__\u001b[0;34m(self, device_type, dtype, enabled, cache_enabled)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfast_dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhpu\u001b[39m.\u001b[39mget_autocast_hpu_dtype()  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mUser specified autocast device_type must be \u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcuda\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m or \u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_enabled \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m enabled \u001b[39mand\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mcommon\u001b[39m.\u001b[39mamp_definitely_not_available() \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: User specified autocast device_type must be 'cuda' or 'cpu'"
     ]
    }
   ],
   "source": [
    "# trainer loading and initialization\n",
    "trainer = Trainer(config, model)\n",
    "\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18 Sep 14:12    INFO  Loading model structure and parameters from saved/BPR-Sep-18-2023_14-12-40.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('recall@10', 0.2388), ('mrr@10', 0.482), ('ndcg@10', 0.2862), ('hit@10', 0.772), ('precision@10', 0.1914)])\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "test_result = trainer.evaluate(test_data)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmh-notes-FjPe97EK-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
